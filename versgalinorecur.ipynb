{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69077743",
   "metadata": {},
   "source": [
    "LIMPIEZA Y COMBINACION DE LAS BASES DE DATOS (PASO 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905abe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vista previa de la base combinada:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivos CSV\n",
    "clientes = pd.read_csv('base_clientes_final.csv')\n",
    "transacciones = pd.read_csv('base_transacciones_final.csv')\n",
    "\n",
    "# Limpiar nombres de columnas por si acaso\n",
    "clientes.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "transacciones.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# Combinar las bases usando 'id',,,\n",
    "base_completa = transacciones.merge(clientes, on='id', how='left')\n",
    "\n",
    "# Llenar nulos en giro_comercio\n",
    "base_completa['giro_comercio'].fillna(\"SIN CLASIFICAR\", inplace=True)\n",
    "\n",
    "# Vista previa\n",
    "print(\"Vista previa de la base combinada:\")\n",
    "#print(base_completa.head())\n",
    "\n",
    "# Guardar base combinada\n",
    "base_completa.to_csv('base_completa.csv', index=False)\n",
    "#print(\"\\n¡Archivo guardado como 'base_completa.csv'!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a636b0f3",
   "metadata": {},
   "source": [
    "DETECCIÓN DE GASTOS RECURRENTES (PASO 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1799338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse que la fecha sea tipo datetime \n",
    "base_completa['fecha'] = pd.to_datetime(base_completa['fecha'])\n",
    "\n",
    "# Crear columna año-mes\n",
    "base_completa['año_mes'] = base_completa['fecha'].dt.to_period('M')\n",
    "\n",
    "# Agrupar por cliente y comercio para contar meses distintos\n",
    "frecuencia_mensual = (\n",
    "    base_completa.groupby(['id', 'comercio'])['año_mes']\n",
    "    .nunique()\n",
    "    .reset_index(name='meses_distintos')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96865cb7",
   "metadata": {},
   "source": [
    "continuacion parte 2 para las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9135e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estadísticas de monto\n",
    "# Calcular promedio, std y número de transacciones por cliente-comercio\n",
    "agrupado_montos = base_completa.groupby(['id', 'comercio'])['monto'].agg(\n",
    "    monto_prom='mean',\n",
    "    monto_std='std',\n",
    "    num_transacciones='count'\n",
    ").reset_index()\n",
    "\n",
    "# Eliminar columnas duplicadas antes de hacer el merge para evitar conflictos de sufijos\n",
    "cols_to_drop = ['monto_prom', 'monto_std', 'num_transacciones']\n",
    "frecuencia_mensual = frecuencia_mensual.drop(columns=[col for col in cols_to_drop if col in frecuencia_mensual.columns])\n",
    "\n",
    "# Unir con frecuencia_mensual\n",
    "frecuencia_mensual = frecuencia_mensual.merge(agrupado_montos, on=['id', 'comercio'], how='left')\n",
    "\n",
    "# Calcular rupturas de meses consecutivos\n",
    "def contar_saltes(meses):\n",
    "    meses_ordenados = sorted(meses.unique())\n",
    "    diferencias = [meses_ordenados[i+1] - meses_ordenados[i] for i in range(len(meses_ordenados)-1)]\n",
    "    return sum([d.n != 1 for d in diferencias])  # d.n convierte a valor numérico\n",
    "\n",
    "rupturas = (\n",
    "    base_completa.groupby(['id', 'comercio'])['año_mes']\n",
    "    .apply(contar_saltes)\n",
    "    .reset_index(name='meses_no_consecutivos')\n",
    ")\n",
    "\n",
    "# Unir con frecuencia_mensual\n",
    "frecuencia_mensual = frecuencia_mensual.merge(rupturas, on=['id', 'comercio'], how='left')\n",
    "\n",
    "# Crear etiquetas\n",
    "\n",
    "# General: recurrente si cumple ≥7 meses, estabilidad en monto y pocos saltos\n",
    "frecuencia_mensual['es_recurrente'] = (\n",
    "    (frecuencia_mensual['meses_distintos'] >= 7) &\n",
    "    (frecuencia_mensual['monto_std'] < 100) &\n",
    "    (frecuencia_mensual['meses_no_consecutivos'] <= 2)\n",
    ").astype(int)\n",
    "\n",
    "# Fuerte: exactamente 12 meses de gasto\n",
    "frecuencia_mensual['es_recurrente_fuerte'] = (\n",
    "    frecuencia_mensual['meses_distintos'] == 12\n",
    ").astype(int)\n",
    "\n",
    "# Vista previa y exportación\n",
    "#print(frecuencia_mensual.sort_values(by='meses_distintos', ascending=False).head())\n",
    "\n",
    "frecuencia_mensual.to_csv('frecuencia_mensual_etiquetada.csv', index=False)\n",
    "#print(\"\\n¡Archivo guardado como 'frecuencia_mensual_etiquetada.csv'!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5e6a1",
   "metadata": {},
   "source": [
    "PREDECIR COMERCIO Y MONTO SIGUIENTE (PASO 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab28755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_mensual_etiquetada = pd.read_csv('frecuencia_mensual_etiquetada.csv')\n",
    "\n",
    "base_modelo = base_completa.merge(\n",
    "    frecuencia_mensual_etiquetada[['id', 'comercio', 'es_recurrente', 'es_recurrente_fuerte']], \n",
    "    on=['id', 'comercio'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filtrar solo los clientes recurrentes fuertes\n",
    "base_no_recurrente = base_modelo[(base_modelo['es_recurrente'] == 0) & (base_modelo['es_recurrente_fuerte'] == 0)].copy()\n",
    "base_no_recurrente = base_no_recurrente.sort_values(['id', 'fecha']) # Ordenar por cliente y fecha\n",
    "\n",
    "# Shift por cliente: comercio y monto siguientes\n",
    "# Calcular targets: comercio y monto siguientes\n",
    "base_no_recurrente['comercio_siguiente'] = (\n",
    "    base_no_recurrente.groupby('id')['comercio'].shift(-1)\n",
    ")\n",
    "base_no_recurrente['monto_siguiente'] = (\n",
    "    base_no_recurrente.groupby('id')['monto'].shift(-1)\n",
    ")\n",
    "\n",
    "# Eliminar la última compra de cada cliente (no hay siguiente)\n",
    "base_no_recurrente = base_no_recurrente.dropna(subset=['comercio_siguiente', 'monto_siguiente'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078a331",
   "metadata": {},
   "source": [
    "Modelo clasificación comercio siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cbe4a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 50855936 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m# Modelo\u001b[39;00m\n\u001b[0;32m     16\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy en test: \u001b[39m\u001b[39m{\u001b[39;00mclf\u001b[39m.\u001b[39mscore(X_test,\u001b[39m \u001b[39my_test)\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1988\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[39m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    190\u001b[0m         X,\n\u001b[0;32m    191\u001b[0m         y,\n\u001b[0;32m    192\u001b[0m         sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight,\n\u001b[0;32m    193\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[39m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m_tree.pyx:153\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:268\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:923\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:892\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_utils.pyx:29\u001b[0m, in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 50855936 bytes"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# One-hot para giro_comercio (o comercio actual)\n",
    "X = base_no_recurrente[['giro_comercio', 'monto']].copy()\n",
    "X = pd.get_dummies(X, columns=['giro_comercio'])\n",
    "\n",
    "y = base_no_recurrente['comercio_siguiente']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy en test: {clf.score(X_test, y_test):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0254e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de que fecha es datetime\n",
    "base_no_recurrente['fecha'] = pd.to_datetime(base_no_recurrente['fecha'])\n",
    "\n",
    "# Ordenar por cliente y fecha\n",
    "base_no_recurrente = base_no_recurrente.sort_values(['id', 'fecha'])\n",
    "\n",
    "# Lags de montos\n",
    "base_no_recurrente['monto_lag1'] = base_no_recurrente.groupby('id')['monto'].shift(1)\n",
    "base_no_recurrente['monto_lag2'] = base_no_recurrente.groupby('id')['monto'].shift(2)\n",
    "\n",
    "# Estadísticas históricas (cálculo expandido)\n",
    "base_no_recurrente['monto_mean'] = base_no_recurrente.groupby('id')['monto'].expanding().mean().shift(1).reset_index(level=0, drop=True)\n",
    "base_no_recurrente['monto_median'] = base_no_recurrente.groupby('id')['monto'].expanding().median().shift(1).reset_index(level=0, drop=True)\n",
    "base_no_recurrente['monto_std'] = base_no_recurrente.groupby('id')['monto'].expanding().std().shift(1).reset_index(level=0, drop=True)\n",
    "\n",
    "# Días desde última compra\n",
    "base_no_recurrente['fecha_lag'] = base_no_recurrente.groupby('id')['fecha'].shift(1)\n",
    "base_no_recurrente['dias_desde_ultima'] = (base_no_recurrente['fecha'] - base_no_recurrente['fecha_lag']).dt.days\n",
    "# Crear dummies sin eliminar la columna original\n",
    "dummies = pd.get_dummies(base_no_recurrente['giro_comercio'], prefix='giro_comercio', drop_first=True)\n",
    "\n",
    "# Concatenar las dummies al DataFrame\n",
    "base_no_recurrente = pd.concat([base_no_recurrente, dummies], axis=1)\n",
    "base_modelo = base_no_recurrente.dropna(subset=[\n",
    "    'monto_lag1', 'monto_lag2', 'monto_mean', 'monto_median', 'monto_std', 'dias_desde_ultima'\n",
    "])\n",
    "# Seleccionar columnas numéricas + one-hot de giro_comercio\n",
    "columnas_modelo = [\n",
    "    'monto_lag1', 'monto_lag2', \n",
    "    'monto_mean', 'monto_median', 'monto_std',\n",
    "    'dias_desde_ultima'\n",
    "] + [col for col in base_modelo.columns if col.startswith('giro_comercio_')]\n",
    "\n",
    "X = base_modelo[columnas_modelo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1884a",
   "metadata": {},
   "source": [
    "Modelo regresión monto siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del monto siguiente: 139.77\n",
      "R² del modelo: 0.0794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "y_monto = base_modelo['monto_siguiente']\n",
    "\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X, y_monto, test_size=0.2, random_state=42)\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg.fit(X_train_m, y_train_m)\n",
    "\n",
    "preds = reg.predict(X_test_m)\n",
    "mse = mean_squared_error(y_test_m, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(f\"RMSE del monto siguiente: {rmse:.2f}\")\n",
    "# Supón que ya tienes tu modelo entrenado y predicciones hechas\n",
    "r2 = r2_score(y_test_m, preds)\n",
    "print(f\"R² del modelo: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b30cdc",
   "metadata": {},
   "source": [
    "PREDECIR TIEMPO HASTA PRÓXIMA COMPRA (PASO 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la fecha esté en formato datetime\n",
    "base_completa = base_no_recurrente\n",
    "base_completa['fecha'] = pd.to_datetime(base_completa['fecha'])\n",
    "\n",
    "# Ordenar por cliente, comercio y fecha (¡fundamental!)\n",
    "base_completa.sort_values(['id', 'comercio', 'fecha'], inplace=True)\n",
    "\n",
    "# Crear columnas con la siguiente fecha y monto por cada pareja (id, comercio)\n",
    "base_completa['fecha_siguiente'] = base_completa.groupby(['id', 'comercio'])['fecha'].shift(-1)\n",
    "base_completa['monto_siguiente'] = base_completa.groupby(['id', 'comercio'])['monto'].shift(-1)\n",
    "\n",
    "# Crear variable target: días hasta la siguiente transacción\n",
    "base_completa['dias_hasta_siguiente'] = (base_completa['fecha_siguiente'] - base_completa['fecha']).dt.days\n",
    "base_train = base_completa.dropna(subset=['dias_hasta_siguiente'])\n",
    "base_completa['dias_entre_compras'] = base_completa.groupby(['id', 'comercio'])['fecha'].diff().dt.days\n",
    "\n",
    "# Estadísticas temporales\n",
    "estadisticas_tiempo = base_completa.groupby(['id', 'comercio'])['dias_entre_compras'].agg(\n",
    "    media_dias_entre_compras='mean',\n",
    "    mediana_dias_entre_compras='median'\n",
    ").reset_index()\n",
    "\n",
    "# Agregar estas estadísticas a base_completa\n",
    "base_completa = base_completa.merge(estadisticas_tiempo, on=['id', 'comercio'], how='left')\n",
    "#base_completa = base_completa.merge(estadisticas_tiempo2, on=['id', 'comercio'], how='left')\n",
    "\n",
    "# --- Preparar datos para regresión de días ---\n",
    "\n",
    "# Filtrar filas que tengan target definido (sin nulos)\n",
    "base_train = base_completa.dropna(subset=['dias_hasta_siguiente'])\n",
    "\n",
    "X = base_train[['monto', 'giro_comercio', 'fecha', 'media_dias_entre_compras', 'mediana_dias_entre_compras']].copy()\n",
    "\n",
    "# Extraer variables de fecha para incluirlas como features\n",
    "X['mes'] = X['fecha'].dt.month\n",
    "X['dia_semana'] = X['fecha'].dt.dayofweek\n",
    "\n",
    "# Eliminar columna fecha porque no la usaremos directamente\n",
    "X.drop(columns=['fecha'], inplace=True)\n",
    "\n",
    "# Convertir variable categórica 'giro_comercio' a variables dummy (one-hot encoding)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Variable objetivo\n",
    "y = base_train['dias_hasta_siguiente']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e1025",
   "metadata": {},
   "source": [
    "Entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE mejorado: 17.47 días\n",
      "Median Absolute Error: 7.07\n",
      "R² del modelo: 0.4297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=49)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "medae = median_absolute_error(y_test, preds)\n",
    "print(f\"MAE mejorado: {mae:.2f} días\")\n",
    "print(f\"Median Absolute Error: {medae:.2f}\")\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"R² del modelo: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529ad41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dia_semana\n- media_dias_entre_compras\n- mediana_dias_entre_compras\n- mes\nFeature names seen at fit time, yet now missing:\n- giro_comercio_4121\n- giro_comercio_ACCESORIOS INDUSTRIALES - NO CLASIFICADOS\n- giro_comercio_FERRETERIAS, ACCESORIOS Y EQUIPO\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m X_comercio \u001b[39m=\u001b[39m X_comercio[X_train\u001b[39m.\u001b[39mcolumns]\n\u001b[0;32m     19\u001b[0m \u001b[39m# Predicción del comercio\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m pred_comercios \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_comercio)\n\u001b[0;32m     21\u001b[0m ultima_compra[\u001b[39m'\u001b[39m\u001b[39mcomercio_estimado\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pred_comercios\n\u001b[0;32m     23\u001b[0m \u001b[39m# 3. Features para predicción de monto\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    906\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    948\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[39m=\u001b[39m validate_data(\n\u001b[0;32m    639\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    640\u001b[0m     X,\n\u001b[0;32m    641\u001b[0m     dtype\u001b[39m=\u001b[39;49mDTYPE,\n\u001b[0;32m    642\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    643\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    644\u001b[0m     ensure_all_finite\u001b[39m=\u001b[39;49mensure_all_finite,\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[39m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[39m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m   2920\u001b[0m     tags \u001b[39m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m tags\u001b[39m.\u001b[39mtarget_tags\u001b[39m.\u001b[39mrequired:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dia_semana\n- media_dias_entre_compras\n- mediana_dias_entre_compras\n- mes\nFeature names seen at fit time, yet now missing:\n- giro_comercio_4121\n- giro_comercio_ACCESORIOS INDUSTRIALES - NO CLASIFICADOS\n- giro_comercio_FERRETERIAS, ACCESORIOS Y EQUIPO\n"
     ]
    }
   ],
   "source": [
    "# 1. Base más reciente de cada persona\n",
    "ultima_compra = base_no_recurrente.sort_values(['id', 'fecha']).groupby('id').tail(1).copy()\n",
    "\n",
    "# 2. Features para predicción de comercio\n",
    "# Crear dummies solo para 'giro_comercio'\n",
    "X_comercio = pd.get_dummies(ultima_compra[['giro_comercio']], drop_first=True)\n",
    "\n",
    "# Agregar 'monto' como columna numérica\n",
    "X_comercio['monto'] = ultima_compra['monto']\n",
    "\n",
    "# Asegurar que tenga todas las columnas del entrenamiento (en el mismo orden)\n",
    "faltantes = set(X_train.columns) - set(X_comercio.columns)\n",
    "for col in faltantes:\n",
    "    X_comercio[col] = 0\n",
    "\n",
    "# Reordenar\n",
    "X_comercio = X_comercio[X_train.columns]\n",
    "\n",
    "# Predicción del comercio\n",
    "pred_comercios = clf.predict(X_comercio)\n",
    "ultima_compra['comercio_estimado'] = pred_comercios\n",
    "\n",
    "# 3. Features para predicción de monto\n",
    "X_monto = ultima_compra[columnas_modelo].copy()\n",
    "X_monto = X_monto.reindex(columns=X_train_m.columns, fill_value=0)\n",
    "\n",
    "# Predicción del monto\n",
    "pred_montos = reg.predict(X_monto)\n",
    "ultima_compra['monto_estimado'] = pred_montos\n",
    "\n",
    "# 4. Features para predicción de días hasta próxima compra\n",
    "X_fecha = ultima_compra[['monto', 'giro_comercio', 'fecha', 'media_dias_entre_compras', 'mediana_dias_entre_compras']].copy()\n",
    "X_fecha['mes'] = X_fecha['fecha'].dt.month\n",
    "X_fecha['dia_semana'] = X_fecha['fecha'].dt.dayofweek\n",
    "X_fecha = X_fecha.drop(columns='fecha')\n",
    "X_fecha = pd.get_dummies(X_fecha, drop_first=True)\n",
    "X_fecha = X_fecha.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Predicción de días\n",
    "pred_dias = rf.predict(X_fecha)\n",
    "ultima_compra['fecha_estimada'] = ultima_compra['fecha'] + pd.to_timedelta(pred_dias.round().astype(int), unit='D')\n",
    "\n",
    "# 5. Tabla final\n",
    "tabla_final = ultima_compra[['id', 'comercio_estimado', 'monto_estimado', 'fecha_estimada']]\n",
    "\n",
    "tabla_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "001dc15ad77babc49301626663976d6caf22cd76978e46ca74a2f3f3b6dfe971"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
